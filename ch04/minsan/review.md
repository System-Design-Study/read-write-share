# 처리율 제한 장치에 필요한 요구사항

처리율 제한 장치를 설계하기 전에, 아래와 같은 정보들을 명확히 설정하는 것이 좋다.

- 처리율 제한 장치의 **종류** _(서버 vs 클라이언트)_
  - API 서버의 처리율을 제한할 것인지, 클라이언트의 처리율(?)을 제한할 것인지
- 처리율 **제한의 대상** _(IP주소, 유저ID, API 엔드포인트)_
- 시스템의 규모
- **분산 환경** 여부
- 사용자에게 처리율 제한 알림 여부

# API 서버의 처리율 제한 장치는 클라이언트에 두면 안 된다

**API 서버의 처리율**을 제한하는 경우, 클라이언트 측에 처리율 제한 장치를 두는 것은 적합하지 않다.

- 클라이언트의 요청은 전달 과정에서 쉽게 위변조 될 수 있기 때문
  - 👉🏻 클라이언트 측에서 아무리 제한하더라도 요청 패킷이 변조될 수 있음

따라서 **API 서버의 처리율을 제한하는 경우**, 제한 장치를 `서버` 또는 `미들웨어`에 두는 것이 적합하다.

# 처리율 제한 알고리즘 선택

각 알고리즘의 장단점을 이해하고, 주어진 요구사항에 적합한 것을 선택할 수 있어야 한다.

- **단시간에 트래픽이 집중되는 경우**
  - 토큰 버킷 알고리즘
  - 이동 윈도우 카운터 알고리즘
- **안정적인 서버의 요청 처리율을 요구하는 경우**
  - 누출 버킷 알고리즘
- **단기간에 트래픽이 몰리지 않으며, 트래픽이 어느정도 예측 가능한 경우** _(👉🏻 일반적이진 않은듯)_
  - 고정 윈도우 카운터

_ex) 깜짝 세일 이벤트로 단시간에 대규모 트래픽 발생할 경우 👉🏻 `누출 버킷 알고리즘`_

# 분산 환경에서 고려해야 할 부분 - 경쟁조건, 동기화

### 1. 병렬 스레드 - 동시성 문제

병렬 스레드로 처리할 경우 **동시성 문제**가 발생할 수 있다.  
이를 제한하기 위해 **락**을 사용할 수도 있지만, 시스템 성능에 영향이 크게 미친다.  
시스템 성능을 크게 해치지 않는 해결 방안은 다음과 같다.

- 루아 스크립트
- 정렬 집합 (`Redis`)

> 👉🏻 해당 기술들에 대해서 깊이 알 필요까지는 없을 것 같지만, **락이 성능을 저하시킬 수 있다**는 점에서 무조건적인 해결책이 될 수 없다는 사실을 인지하는 것이 좋을 것 같다.

### 2. 분산 환경 - 동기화

**여러 대의 처리율 장치**를 사용하는 경우 동기화 문제가 중요하게 다뤄진다.

- 2장에서 `무상태 서버`를 설계하는 과정에서도 살펴본 바 있음

마찬가지로 대규모 서비스를 운영하기 위해, **처리율 장치** 또한 **장치를 여러 대로 분산하여 운영할 여지**가 충분히 존재한다.

- 이때 특정 유저의 처리율을 확인하려면, 먼저 **어떤 유저인지**부터 확인해야 함

여기서 고려해야 할 부분은 `처리율 제한의 대상 정보가 여러 서버에 분산되어 저장될 수 있다`는 점이다. _(ex. IP별 카운터 값, 유저별 카운터 값 ...)_  
👉🏻 이 경우, 무상태 서버와 비슷하게 **상태 값을 외부로 분리하는 방법**으로 해결할 수 있다.

> 책에서는 모든 제한 장치가 하나의 `Redis` 저장소를 참조하도록 설계했다.
